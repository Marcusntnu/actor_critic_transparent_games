{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module\n",
    "import experiment\n",
    "\n",
    "# Use the classes and functions\n",
    "games = [experiment.GameOfChicken]  # Add your game classes\n",
    "\n",
    "experiment_runner = experiment.ExperimentRunner(\n",
    "    games=games,\n",
    "    repetitions=2,  # Define the number of repetitions for each experiment\n",
    "    results_dir='results/results_0',  # Directory to save the results => Loop can be made to save \n",
    "    analysis_dir='results/analysis_0',  # Directory to save the analysis\n",
    "    rounds_per_experiment=2000,  # Number of rounds for each experiment\n",
    "    base_lr=0.02,  # Set your desired base learning rate\n",
    "    batch_size=128,  # Set your desired batch size\n",
    "    decay_rate=0.95  # Set your desired decay rate\n",
    ")\n",
    "\n",
    "# Run the experiments\n",
    "experiment_runner.run_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from joblib import Parallel, delayed\n",
    "import platform\n",
    "import experiment\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration\n",
    "metric_titles = {\n",
    "    'actor_losses_a': 'Actor Loss A',\n",
    "    'critic_losses_a': 'Critic Loss A',\n",
    "    'actor_losses_b': 'Actor Loss B',\n",
    "    'critic_losses_b': 'Critic Loss B',\n",
    "    'actions_a': 'Actions A',\n",
    "    'actions_b': 'Actions B',\n",
    "    'policy_history_a': 'Policy History A',\n",
    "    'policy_history_b': 'Policy History B',\n",
    "    'rewards_a': 'Rewards A',\n",
    "    'rewards_b': 'Rewards B',\n",
    "    # Add other metrics as needed\n",
    "}\n",
    "\n",
    "def load_results(file):\n",
    "    \"\"\"Load results from a single file.\"\"\"\n",
    "    try:\n",
    "        with gzip.open(file, 'rt', encoding='UTF-8') as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "def flatten_list(data):\n",
    "    \"\"\"Flatten a nested list without recursion.\"\"\"\n",
    "    stack = [data]\n",
    "    flattened = []\n",
    "    while stack:\n",
    "        current = stack.pop()\n",
    "        if isinstance(current, list):\n",
    "            stack.extend(reversed(current))\n",
    "        else:\n",
    "            flattened.append(current)\n",
    "    return flattened\n",
    "\n",
    "def flatten_policy_data(policy_list, continuous):\n",
    "    \"\"\"Flatten policy data while preserving innermost policy lists.\"\"\"\n",
    "    stack = [(policy_list, 0)]\n",
    "    flattened_list = []\n",
    "    while stack:\n",
    "        current, depth = stack.pop()\n",
    "        if isinstance(current, list) and depth < 2:\n",
    "            stack.extend((item, depth + 1) for item in reversed(current))\n",
    "        else:\n",
    "            flattened_list.append(current if not continuous else [current[0][0], current[1][0]])\n",
    "    return flattened_list\n",
    "\n",
    "def precompute_rewards(game_class, action_labels):\n",
    "    game_instance = game_class()\n",
    "    rewards = {}\n",
    "    for action_a in action_labels:\n",
    "        for action_b in action_labels:\n",
    "            reward_a, reward_b, _, _, _ = game_instance.step(action_a, action_b)\n",
    "            rewards[(action_a, action_b)] = (reward_a, reward_b)\n",
    "    return rewards\n",
    "\n",
    "def calculate_rewards_vectorized(actions_a, actions_b, precomputed_rewards, continuous_actions, game_class):\n",
    "    if continuous_actions:\n",
    "        game_instance = game_class()\n",
    "        rewards = np.array([game_instance.step(action_a, action_b)[:2] for action_a, action_b in zip(actions_a, actions_b)])\n",
    "        return rewards[:, 0], rewards[:, 1]\n",
    "    else:\n",
    "        rewards = np.array([precomputed_rewards[(action_a, action_b)] for action_a, action_b in zip(actions_a, actions_b)])\n",
    "        return rewards[:, 0], rewards[:, 1]\n",
    "\n",
    "def save_dataframe(df, results_dir, metric, game):\n",
    "    df['Game'] = game\n",
    "    df['Transparency A'] = df['Transparency A'].astype('category')\n",
    "    df['Transparency B'] = df['Transparency B'].astype('category')\n",
    "    df['Game'] = df['Game'].astype('category')\n",
    "    file_path = os.path.join(results_dir, f\"{metric}.parquet\")\n",
    "    df.to_parquet(file_path, index=False, engine=\"pyarrow\")\n",
    "\n",
    "def load_dataframe(metric, results_dir):\n",
    "    file_path = os.path.join(results_dir, f\"{metric}.parquet\")\n",
    "    if os.path.exists(file_path):\n",
    "        return pd.read_parquet(file_path, engine=\"pyarrow\")\n",
    "    return None\n",
    "\n",
    "def process_file(file, continuous_games, metric, action_labels_dict):\n",
    "    data = load_results(file)\n",
    "    if data is None:\n",
    "        return None\n",
    "\n",
    "    seed = data.get('seed')\n",
    "    transparency_a = data.get('transparency_a')\n",
    "    transparency_b = data.get('transparency_b')\n",
    "    game = data.get('game')\n",
    "    continuous = (game in continuous_games)\n",
    "\n",
    "    if 'policy' in metric:\n",
    "        values = flatten_policy_data(data.get(metric, []), continuous)\n",
    "    else:\n",
    "        values = flatten_list(data.get(metric, []))\n",
    "\n",
    "    step_data = {\n",
    "        'Seed': seed,\n",
    "        'Step': list(range(len(values))),\n",
    "        'Transparency A': [transparency_a] * len(values),\n",
    "        'Transparency B': [transparency_b] * len(values),\n",
    "        metric_titles[metric]: values,\n",
    "        'Game': [game] * len(values)\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(step_data)\n",
    "\n",
    "    if metric in ['actions_a', 'actions_b']:\n",
    "        actions_a = flatten_list(data.get('actions_a', []))\n",
    "        actions_b = flatten_list(data.get('actions_b', []))\n",
    "        game_class = getattr(experiment, game)\n",
    "        if game in continuous_games:\n",
    "            precomputed_rewards = None\n",
    "        else:\n",
    "            action_labels = list(range(len(action_labels_dict[game])))\n",
    "            precomputed_rewards = precompute_rewards(game_class, action_labels)\n",
    "\n",
    "        rewards_a, rewards_b = calculate_rewards_vectorized(actions_a, actions_b, precomputed_rewards, continuous, game_class)\n",
    "        rewards_df_a = pd.DataFrame({\n",
    "            'Seed': seed,\n",
    "            'Step': list(range(len(rewards_a))),\n",
    "            'Rewards A': rewards_a,\n",
    "            'Transparency A': [transparency_a] * len(rewards_a),\n",
    "            'Transparency B': [transparency_b] * len(rewards_a),\n",
    "            'Game': [game] * len(rewards_a)\n",
    "        })\n",
    "        rewards_df_b = pd.DataFrame({\n",
    "            'Seed': seed,\n",
    "            'Step': list(range(len(rewards_b))),\n",
    "            'Rewards B': rewards_b,\n",
    "            'Transparency A': [transparency_a] * len(rewards_b),\n",
    "            'Transparency B': [transparency_b] * len(rewards_b),\n",
    "            'Game': [game] * len(rewards_b)\n",
    "        })\n",
    "        save_dataframe(rewards_df_a, os.path.dirname(file), 'rewards_a', game)\n",
    "        save_dataframe(rewards_df_b, os.path.dirname(file), 'rewards_b', game)\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_metric(results_dir, metric, continuous_games, action_labels_dict):\n",
    "    \"\"\"Process a single metric and save to disk.\"\"\"\n",
    "    existing_df = load_dataframe(metric, results_dir)\n",
    "    if existing_df is not None:\n",
    "        logger.info(f\"Loaded existing {metric} dataframe for {results_dir}\")\n",
    "        return existing_df\n",
    "\n",
    "    files = [os.path.join(results_dir, file) for file in os.listdir(results_dir) if file.endswith('.json.gz')]\n",
    "    dfs = Parallel(n_jobs=-2)(delayed(process_file)(file, continuous_games, metric, action_labels_dict) for file in files)\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    game = combined_df['Game'].iloc[0] if not combined_df.empty else 'Unknown'\n",
    "    save_dataframe(combined_df, results_dir, metric, game)\n",
    "    return combined_df\n",
    "\n",
    "def process_results(results_dir, continuous_games, metrics, action_labels_dict):\n",
    "    \"\"\"Process results for all metrics.\"\"\"\n",
    "    for metric in metrics.keys():\n",
    "        df = process_metric(results_dir, metric, continuous_games, action_labels_dict)\n",
    "        logger.info(f\"Processed metric {metric} for {results_dir}\")\n",
    "\n",
    "def process_dir_wrapper(results_dir, continuous_games, metrics, action_labels_dict):\n",
    "    try:\n",
    "        logger.info(f\"Processing {results_dir}\")\n",
    "        process_results(results_dir, continuous_games, metrics, action_labels_dict)\n",
    "        logger.info(f\"Completed processing {results_dir}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {results_dir}: {e}\")\n",
    "\n",
    "        \n",
    "\n",
    "results_plot = 'results_plot'\n",
    "results_dir_prefix = \"results/results_\"\n",
    "results_dirs = [f\"{results_dir_prefix}{i}\" for i in range(0, 8)]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(results_plot, exist_ok=True)\n",
    "    existing_dirs = [dir for dir in results_dirs if os.path.exists(dir)]\n",
    "    logger.info(f\"Processing directories: {existing_dirs}\")\n",
    "\n",
    "    continuous_games = [\"BertrandCompetition\"]  # Add more continuous games if needed\n",
    "    action_labels_dict = {\n",
    "    'GameOfChicken': {0: 'Swerve', 1: 'Straight'},\n",
    "    'PrisonersDilemma': {0: 'Cooperate', 1: 'Defect'},\n",
    "    'StagHunt': {0: 'Hunt Hare', 1: 'Hunt Stag'},\n",
    "    'EntryDeterrenceGame': {0: 'Low Price', 1: 'High Price'},\n",
    "    'StackelbergGame': {i: f'Production Level {i}' for i in range(10)},\n",
    "    'UltimatumGame': {i: f'Offer {i} Units' for i in range(11)},\n",
    "    'PublicGoodsGame': {i: f'Contribute {i} Units' for i in range(11)},\n",
    "    'BargainingGame': {i: f'Offer {i} Units' for i in range(11)},\n",
    "    'MatchingPennies': {0: 'Heads', 1: 'Tails'},\n",
    "    'RockPaperScissors': {0: 'Rock', 1: 'Paper', 2: 'Scissors'},\n",
    "    'BattleOfTheSexes': {0: \"A's Preferred\", 1: \"B's Preferred\"},\n",
    "    'CoordinationGame': {0: 'Option 1', 1: 'Option 2'},\n",
    "    'BertrandCompetition': {0: 'Price'}\n",
    "    }\n",
    "\n",
    "    if platform.system() != 'Darwin':\n",
    "        Parallel(n_jobs=1)(delayed(process_dir_wrapper)(dir, continuous_games, metric_titles, action_labels_dict) for dir in existing_dirs)\n",
    "    else:\n",
    "        for dir in existing_dirs:\n",
    "            process_dir_wrapper(dir, continuous_games, metric_titles, action_labels_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to load and display a specific metric's dataframe from a given directory\n",
    "def load_and_display_metric(results_dir, metric):\n",
    "    file_path = os.path.join(results_dir, f\"{metric}.parquet\")\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_parquet(file_path)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"File for {metric} not found in {results_dir}\")\n",
    "        return None\n",
    "\n",
    "results_dir = \"results/results_0\"  # change to the directory you want to check\n",
    "metric = \"actor_losses_a\"  # change to the metric you want to check\n",
    "\n",
    "# Load and display the metric\n",
    "df = load_and_display_metric(results_dir, metric)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
